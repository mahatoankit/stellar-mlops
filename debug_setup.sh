#!/bin/bash
# =============================================================================
# STELLAR CLASSIFICATION MLOPS - DEBUG & TROUBLESHOOTING SCRIPT
# =============================================================================

echo "üîç Debugging Stellar Classification MLOps Setup..."
echo "=================================================="

# Get project directory
PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$PROJECT_DIR"

echo "üìÅ Project Directory: $PROJECT_DIR"
echo ""

# Check environment
echo "üêç Environment Status:"
echo "----------------------"
if command -v conda &> /dev/null; then
    echo "‚úÖ Conda available"
    conda info --envs | grep stellar-mlops || echo "‚ùå stellar-mlops environment not found"
else
    echo "‚ùå Conda not available"
fi
echo ""

# Check PostgreSQL
echo "üêò PostgreSQL Status:"
echo "--------------------"
if systemctl is-active --quiet postgresql; then
    echo "‚úÖ PostgreSQL service running"
    sudo -u postgres psql -c "\l" | grep airflow_db && echo "‚úÖ airflow_db exists" || echo "‚ùå airflow_db missing"
else
    echo "‚ùå PostgreSQL service not running"
fi
echo ""

# Check Airflow configuration
echo "‚öôÔ∏è Airflow Configuration:"
echo "-------------------------"
if [ -f "airflow.cfg" ]; then
    echo "‚úÖ airflow.cfg exists"
    echo "DAGs folder: $(grep 'dags_folder' airflow.cfg)"
    echo "Load examples: $(grep 'load_examples' airflow.cfg)"
    echo "Database: $(grep 'sql_alchemy_conn' airflow.cfg)"
    echo "Executor: $(grep '^executor' airflow.cfg)"
else
    echo "‚ùå airflow.cfg not found"
fi
echo ""

# Check DAG file
echo "üìÑ DAG File Status:"
echo "------------------"
if [ -f "airflow/dags/stellar_pipeline_dag.py" ]; then
    echo "‚úÖ stellar_pipeline_dag.py exists"
    echo "File size: $(stat -c%s airflow/dags/stellar_pipeline_dag.py) bytes"
else
    echo "‚ùå stellar_pipeline_dag.py not found"
fi
echo ""

# Check if environment can be activated
echo "üîÑ Environment Activation Test:"
echo "------------------------------"
if source $(conda info --base)/etc/profile.d/conda.sh && conda activate stellar-mlops; then
    echo "‚úÖ Environment activation successful"
    
    # Set environment variables
    export AIRFLOW_HOME=$PROJECT_DIR
    export PYTHONPATH=$PROJECT_DIR/src:$PYTHONPATH
    
    echo "üîç Testing DAG import..."
    python -c "
import sys, os
sys.path.append('$PROJECT_DIR/src')
os.chdir('$PROJECT_DIR')
try:
    from airflow.dags.stellar_pipeline_dag import dag
    print('‚úÖ DAG imported successfully!')
    print(f'DAG ID: {dag.dag_id}')
    print(f'DAG description: {dag.description}')
except Exception as e:
    print(f'‚ùå DAG import failed: {e}')
    import traceback
    traceback.print_exc()
"
    
    echo "üîç Testing Airflow DAG detection..."
    airflow dags list | grep stellar && echo "‚úÖ Stellar DAG detected by Airflow" || echo "‚ùå Stellar DAG not detected by Airflow"
    
else
    echo "‚ùå Environment activation failed"
fi
echo ""

# Check required packages
echo "üì¶ Required Packages:"
echo "--------------------"
if conda activate stellar-mlops; then
    python -c "
packages = ['airflow', 'pandas', 'scikit-learn', 'mlflow', 'fastapi', 'psycopg2']
for pkg in packages:
    try:
        __import__(pkg)
        print(f'‚úÖ {pkg}')
    except ImportError:
        print(f'‚ùå {pkg} - missing')
"
fi
echo ""

# Check database connectivity
echo "üîó Database Connectivity:"
echo "------------------------"
if conda activate stellar-mlops; then
    export AIRFLOW_HOME=$PROJECT_DIR
    echo "Testing Airflow database connection..."
    airflow db check && echo "‚úÖ Database connection successful" || echo "‚ùå Database connection failed"
fi
echo ""

echo "üèÅ Debug complete!"
echo ""
echo "üí° Common solutions:"
echo "   1. If PostgreSQL is not running: sudo systemctl start postgresql"
echo "   2. If database doesn't exist: Re-run ./setup.sh"
echo "   3. If DAG not detected: Check airflow/dags/stellar_pipeline_dag.py exists"
echo "   4. If import fails: Check src/ directory and PYTHONPATH"
echo "   5. If still using SQLite: Check airflow.cfg sql_alchemy_conn setting"